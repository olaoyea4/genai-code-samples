{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b6cf1f-88f2-480c-920e-63f1b1f62899",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with Amazon Bedrock - Enhancing Chat Applications with RAG\n",
    "\n",
    "> *PLEASE NOTE: This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*\n",
    "\n",
    "---\n",
    "\n",
    "## Chat with LLMs Overview\n",
    "\n",
    "Conversational interfaces such as chatbots and virtual assistants can be used to enhance the user experience for your customers. Chatbots can be used in a variety of applications, such as customer service, sales, and e-commerce, to provide quick and efficient responses to users.\n",
    "\n",
    "The key technical detail which we need to include in our system to enable a chat feature is conversational memory. This way, customers can ask follow up questions and the LLM will understand what the customer has already said in the past. The image below shows how this is orchestrated at a high level.\n",
    "\n",
    "![Amazon Bedrock - Conversational Interface](./images/chatbot_bedrock.png)\n",
    "\n",
    "## Extending Chat with RAG\n",
    "\n",
    "However, in our workshop's situation, we want to be able to enable a customer to ask follow up questions regarding documentation we provide through RAG. This means we need to build a system which has conversational memory AND contextual retrieval built into the text generation.\n",
    "\n",
    "![4](./images/context-aware-chatbot.png)\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9a38a-813e-4bcf-8dfd-4c17baf0cced",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup `boto3` Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bbd32-a1d0-4c29-8a53-9381cdd6b377",
   "metadata": {},
   "source": [
    "#### Libraries needed for the installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2baa9ca-658d-4c26-bdd1-97d937a4129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain>=0.1.11 in /opt/conda/lib/python3.10/site-packages (0.1.13)\n",
      "Requirement already satisfied: transformers<5,>=4.24 in /opt/conda/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: faiss-cpu<2,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: pypdf<4,>=3.8 in /opt/conda/lib/python3.10/site-packages (3.17.4)\n",
      "Requirement already satisfied: pinecone-client==2.2.4 in /opt/conda/lib/python3.10/site-packages (2.2.4)\n",
      "Requirement already satisfied: apache-beam==2.52. in /opt/conda/lib/python3.10/site-packages (2.52.0)\n",
      "Requirement already satisfied: tiktoken==0.5.2 in /opt/conda/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /opt/conda/lib/python3.10/site-packages (7.8.2)\n",
      "Requirement already satisfied: matplotlib==3.8.2 in /opt/conda/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: anthropic==0.9.0 in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: llama-index==0.9.0 in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (4.12.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (2.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (1.26.19)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==2.2.4) (1.24.4)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (3.10.4)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (1.9.5)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (1.59.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.22.0)\n",
      "Requirement already satisfied: js2py<1,>=0.74 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.74)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (4.17.3)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.6.1)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (23.2)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (4.8.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (4.25.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (2023.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (2024.5.15)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.22.0)\n",
      "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (11.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /opt/conda/lib/python3.10/site-packages (from apache-beam==2.52.) (0.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (3.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from anthropic==0.9.0) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from anthropic==0.9.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from anthropic==0.9.0) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from anthropic==0.9.0) (1.10.16)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from anthropic==0.9.0) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from anthropic==0.9.0) (0.19.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.0) (2.0.30)\n",
      "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (0.5.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (4.12.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (2023.6.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (1.6.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (1.35.13)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (2.2.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (8.4.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.9.0) (0.9.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (4.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.1.11) (0.1.82)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=4.24) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=4.24) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=4.24) (0.4.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7) (0.2.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.7 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7) (3.6.7)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7) (8.25.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7) (1.1.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.11) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.11) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.11) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.11) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.11) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic==0.9.0) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic==0.9.0) (1.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index==0.9.0) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama-index==0.9.0) (3.21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index==0.9.0) (1.14.1)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam==2.52.) (0.6.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam==2.52.) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic==0.9.0) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic==0.9.0) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic==0.9.0) (0.14.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8,>=7) (4.9.0)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /opt/conda/lib/python3.10/site-packages (from js2py<1,>=0.74->apache-beam==2.52.) (5.2)\n",
      "Requirement already satisfied: pyjsparser>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from js2py<1,>=0.74->apache-beam==2.52.) (2.7.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.1.11) (3.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.52.) (0.20.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.0) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.0) (1.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.0) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index==0.9.0) (1.0.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (7.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index==0.9.0) (2024.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8,>=7) (0.8.4)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.24.0)\n",
      "Requirement already satisfied: jupyterlab<4.2,>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (4.1.6)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (6.4.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8,>=7) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets<8,>=7) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8,>=7) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8,>=7) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8,>=7) (0.2.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (23.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (5.10.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.20.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (26.0.3)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.18.1)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.0.4)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (6.29.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.2.5)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.9.25)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.8.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.2,>=4.1.1->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (5.9.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.1.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (4.2.2)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.1.1)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.3.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.20.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (20.11.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (24.6.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.7->ipywidgets<8,>=7) (2.9.0.20240316)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install  \\\n",
    "    \"langchain>=0.1.11\" \\\n",
    "    \"transformers>=4.24,<5\" \\\n",
    "    \"faiss-cpu>=1.7.4,<2\" \\\n",
    "    \"pypdf>=3.8,<4\" \\\n",
    "    pinecone-client==2.2.4 \\\n",
    "    apache-beam==2.52. \\\n",
    "    tiktoken==0.5.2 \\\n",
    "    \"ipywidgets>=7,<8\" \\\n",
    "    matplotlib==3.8.2 \\\n",
    "    anthropic==0.9.0 \\\n",
    "    llama-index==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59cc5335-0f42-4bac-b668-93f5142d6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "region = os.environ.get(\"AWS_REGION\")\n",
    "boto3_bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62d078-0ab8-4ddc-93f9-bebd0bbde6f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df84fcb7-a699-419e-aeff-d80676a5b20e",
   "metadata": {},
   "source": [
    "### Use the following COT prompt to test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e7b648f-919d-4595-92b7-a2aae5bf86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Human: You are a supply chain inspector. Your job is to assess the risk of a supplier. You measure the supplier risk by evaluating the supplier across three dimensions: country, size, and reputation.\\nCountry - north America and west Europe countries are considered low risk. The rest of the world is considered medium risk.\\nSize - supplier with over 1000 employees is low risk. Supplier with 50 to 999 employees is medium risk, and a supplier with under 50 employees is high risk.\\nReputation - reputation scores are between 1 to 10 where a score of 1 to 3 is low risk, a score of 4 to 7 is medium risk, and a reputation score of 8 to 10 is high risk.\\nThe risk formula is to take the maximum risk across the three dimensions.\\n##\\nExample:\\nSupplier: A\\nCountry: Chad\\nSize: 30\\nReputation: 8\\nLet's think step by step:\\nChad is not in North America or West Europe therefore country risk is medium.\\nA size of 30 is below 50 and therefore considered high risk.\\nA reputation score of 8 is between 8 to 10 and therefore considered high risk.\\nFinal Answer taking the maximum risk among all: Supplier A is at High risk.\\n##\\nSupplier: B\\nCountry: USA\\nSize: 40\\nReputation: 2\\nLet's think step by step: \\nAssistant: \"\n",
    "\n",
    "\n",
    "model_output = \" Okay, let's evaluate Supplier B:\\n\\n- Country: USA is in North America, so the country risk is low.\\n\\n- Size: 40 employees is below 50, so the size risk is high. \\n\\n- Reputation: A score of 2 is between 1-3, so the reputation risk is low.\\n\\nTo determine the overall risk, we take the maximum risk across the three dimensions. \\n\\nThe maximum risk for Supplier B is high due to its small size.\\n\\nTherefore, my assessment is that Supplier B is at high risk overall.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c5623-2e17-452e-9491-5d9e36718922",
   "metadata": {},
   "source": [
    "---\n",
    "## Using LangChain for Conversation Memory\n",
    "\n",
    "We will use LangChain's `ConversationBufferMemory` class provides an easy way to capture conversational memory for LLM chat applications. Let's check out an example of Claude being able to retrieve context through conversational memory below.\n",
    "\n",
    "Similar to the last workshop, we will use both a prompt template and a LangChain LLM for this example. Note that this time our prompt template includes a `{history}` variable where our chat history will be included to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b55b843-694b-428c-8c5b-38cc79479267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "CHAT_PROMPT_TEMPLATE = '''You are a helpful conversational assistant.\n",
    "{history}\n",
    "\n",
    "Human: {human_input}\n",
    "\n",
    "Assistant:\n",
    "'''\n",
    "PROMPT = PromptTemplate.from_template(CHAT_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ec8e944-c32f-420c-8b18-0051587bd029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "\n",
    "llm = Bedrock(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=\"anthropic.claude-instant-v1\",\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 500,\n",
    "        \"temperature\": 0.9,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759385ea-e5e5-47c8-81fc-8795cc01444f",
   "metadata": {},
   "source": [
    "The `ConversationBufferMemory` class is instantiated here and you will notice that we use Claude specific human and assistant prefixes. When we initialize the memory, the history is blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b2fd025-3c34-4547-bb46-4b45adcdf48e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(human_prefix=\"\\nHuman\", ai_prefix=\"\\nAssistant\")\n",
    "history = memory.load_memory_variables({})['history']\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52886c9-0d81-470d-9ec3-3ab2d3b9d282",
   "metadata": {},
   "source": [
    "We now ask Claude a simple question \"How can I check for imbalances in my model?\". The LLM responds to the question and we can use the `add_user_message` and `add_ai_message` functions to save the input and output into memory. We can then retrieve the entire conversation history and print the response. Currently the model will still return answer using the data it was trained upon. Further will examine how to get a curated answer using our own FAq's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a93a219-bba7-421e-88a4-e8db9d0c6c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Human: How can I check for imbalances in my model?\n",
       "\n",
       "Assistant: Here are some things you can do to check for and address potential imbalances in your machine learning model:\n",
       "\n",
       "- Evaluate model performance on different demographic groups. Check error rates, accuracy,etc. for groups defined by attributes like gender, age, location, etc. Large differences could indicate bias.\n",
       "\n",
       "- Review training data for uneven or unrepresentative coverage of different groups. Your model is only as fair as the data it learns from. Check for biases in data collection or labeling.\n",
       "\n",
       "- Perform bias-mitigation techniques like reweighting or oversampling underrepresented groups in training. This can help balance the model's experience. \n",
       "\n",
       "- Adjust decision thresholds for different groups to account for natural variance and achieve fair outcomes rather than just equal error rates. \n",
       "\n",
       "- Conduct demographic parity tests to ensure model outputs are not overly correlated with sensitive attributes like those that could lead to direct or indirect discrimination.\n",
       "\n",
       "- Get feedback from a diverse set of users and experts on how the model may treat or perceive different demographic profiles. Look for unintended harms.\n",
       "\n",
       "- Regularly monitor model performance over time as data, user profiles or environments change to catch new imbalances that emerge. Fairness is an ongoing process.\n",
       "\n",
       "The key is having transparency into a model's behavior for different subpopulations and adjusting accordingly based on empirical evidence of unfair impacts or biases. Continuous evaluation helps catch issues early."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_input = 'How can I check for imbalances in my model?'\n",
    "\n",
    "prompt_data = PROMPT.format(human_input=human_input, history=history)\n",
    "ai_output = llm(prompt_data)\n",
    "\n",
    "memory.chat_memory.add_user_message(human_input)\n",
    "memory.chat_memory.add_ai_message(ai_output.strip())\n",
    "history = memory.load_memory_variables({})['history']\n",
    "display(Markdown(f'{history}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b85a29-c5de-4f98-a4ce-3192033db4c5",
   "metadata": {},
   "source": [
    "Now we will ask a follow up question about the kind of imbalances does it detect and save the input and outputs again. Notice how the model is able to understand that when the human says \"it\", because it has access to the context of the chat history, the model is able to accurately understand what the user is asking about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c43af486-8e4e-4525-8a63-767cf38027c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Here are some common types of imbalances that can be detected when checking a machine learning model:\n",
       "\n",
       "- Statistical parity/demographic disparity - When the model's outcomes are unevenly distributed across demographic groups like gender or race. For example, approval rates differ significantly.\n",
       "\n",
       "- Equalized odds/predictive parity - When the model has different true/false positive rates or precision/recall between groups for the same target variable. For example, higher error rates for one group. \n",
       "\n",
       "- Calibration - When the model's confidence in its predictions is not well-aligned between demographic groups. It may be over- or under-confident for some populations.\n",
       "\n",
       "- Treatment equality - When similar individuals from different demographic groups are assigned meaningfully different model outputs or treatments without justification. \n",
       "\n",
       "- Disparate mistreatment - When the model systematically disadvantages certain groups even when they have the same characteristics as others. \n",
       "\n",
       "- Redlining - When geographic boundary or regional biases emerge, such as better performance in urban vs rural areas.\n",
       "\n",
       "- Feedback loops - When the model reinforces pre-existing biases over time due to data or decisions made on its previous outcomes.\n",
       "\n",
       "- Proxy variables - When non-protected attributes serve as a proxy for protected ones, still leading to potential discrimination.\n",
       "\n",
       "Checking for imbalances in these types of fairness metrics is important to ensure a model is equitable in how it perceives and treats different segments of the population."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_input = 'What kind does it detect?'\n",
    "\n",
    "prompt_data = PROMPT.format(human_input=human_input, history=history)\n",
    "ai_output = llm(prompt_data)\n",
    "\n",
    "memory.chat_memory.add_user_message(human_input)\n",
    "memory.chat_memory.add_ai_message(ai_output.strip())\n",
    "#display(Markdown(f'{history}'))\n",
    "display(Markdown(f'{ai_output}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1aa15b-e4c8-40cd-851e-6cb3f814d907",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating a class to help facilitate conversation\n",
    "\n",
    "To help create some structure around these conversations, we create a custom `Conversation` class below. This class will hold a stateful conversational memory and be the base for conversational RAG later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfd31140-0b15-40cb-992b-6688b06998bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, client, model_id: str=\"anthropic.claude-instant-v1\") -> None:\n",
    "        \"\"\"instantiates a new rag based conversation\n",
    "\n",
    "        Args:\n",
    "            model_id (str, optional): which bedrock model to use for the conversational agent. Defaults to \"anthropic.claude-instant-v1\".\n",
    "        \"\"\"\n",
    "\n",
    "        # instantiate memory\n",
    "        self.memory = ConversationBufferMemory(human_prefix=\"\\nHuman\", ai_prefix=\"\\nAssistant\")\n",
    "\n",
    "        # instantiate LLM connection\n",
    "        self.llm = Bedrock(\n",
    "            client=client,\n",
    "            model_id=model_id,\n",
    "            model_kwargs={\n",
    "                \"max_tokens_to_sample\": 500,\n",
    "                \"temperature\": 0.9,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def ai_respond(self, user_input: str=None):\n",
    "        \"\"\"responds to the user input in the conversation with context used\n",
    "\n",
    "        Args:\n",
    "            user_input (str, optional): user input. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            ai_output (str): response from AI chatbot\n",
    "        \"\"\"\n",
    "\n",
    "        # format the prompt with chat history and user input\n",
    "        history = self.memory.load_memory_variables({})['history']\n",
    "        llm_input = PROMPT.format(history=history, human_input=user_input)\n",
    "\n",
    "        # respond to the user with the LLM\n",
    "        ai_output = self.llm(llm_input).strip()\n",
    "\n",
    "        # store the input and output\n",
    "        self.memory.chat_memory.add_user_message(user_input)\n",
    "        self.memory.chat_memory.add_ai_message(ai_output.strip())\n",
    "\n",
    "        return ai_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257604ed-7971-4963-9eb3-cffc301f6c30",
   "metadata": {},
   "source": [
    "Let's see the class in action with two contextual questions. Again, notice the model is able to correctly interpret the context because it has memory of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa6e05b9-9932-4d96-8a6b-5f26cb020660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = Conversation(client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eee3ce08-520d-465b-8846-56b1df6716f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some things you can do to check for and address potential imbalances in your machine learning model:\n",
       "\n",
       "- Evaluate model performance on different demographic groups. Check accuracy, precision, recall etc. broken down by things like gender, age, race, income level etc. Significant differences could indicate unfairness.\n",
       "\n",
       "- Use bias metrics like statistical parity difference, equal opportunity difference, disparate impact ratio to directly measure bias between groups. Tools like Tensorflow Model Analysis can help with this.\n",
       "\n",
       "- Oversample or undersample data to balance groups and re-evaluate model. See if performance changes significantly. \n",
       "\n",
       "- Try debiasing techniques like adversarial debiasing or prejudice remover to reduce proxy variables encoding protected attributes from the model. Re-evaluate.\n",
       "\n",
       "- Use a balanced training objective like equalized odds or equal opportunity to explicitly optimize for fairness between groups during training.\n",
       "\n",
       "- Check feature importance - if a few features related to protected attributes have outsized importance, it could indicate reliance on unfair proxies. \n",
       "\n",
       "- Get a model provenance report listing the data, parameters and training process. More transparency helps identify potential sources of bias.\n",
       "\n",
       "- Consult literature and guidelines on mitigating bias from groups like ML fairness community, FATML etc for recommended validation strategies.\n",
       "\n",
       "The key is evaluating on multiple relevant metrics and demographic splits to test for unintended discrimination or unfairness in your model. Continual monitoring is also important."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = chat.ai_respond('How can I check for imbalances in my model?')\n",
    "display(Markdown(f'{output}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02a080fa-5930-4ce8-89d7-03a89fec9fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some common types of imbalances that model checking aims to detect:\n",
       "\n",
       "- Demographic imbalances - Where the model performs differently based on attributes like gender, age, race, income level etc. This includes differences in accuracy, false positive/negative rates between groups.\n",
       "\n",
       "- Class imbalance - When the distribution of target classes is uneven in the training data. For example, if one class only makes up 5% of records but is critical. This can skew models. \n",
       "\n",
       "- Feature covariate imbalance - When predictive features are correlated with protected attributes. Models may rely on these proxy variables rather than direct targets.\n",
       "\n",
       "- Missing data imbalance - If data is incomplete in a biased way, like certain groups having missing values more often. Imputation can propagate this bias.\n",
       "\n",
       "- Selection bias - When the training data doesn't accurately represent the population of interest, due to issues in how the data was originally collected or labeled. \n",
       "\n",
       "- Multicollinearity - High correlation between predictors can cause overfitting to specific redundant features instead of general patterns. \n",
       "\n",
       "- Catastrophic forgetting - Models struggle to maintain performance on older/minority data points as they learn from new/majority data.\n",
       "\n",
       "- Dataset shift - When the joint distribution of features and labels changes between training and inference environments.\n",
       "\n",
       "So in summary, model checking tries to identify unfairness, inefficiencies or fragilities in a model that stem from skew, imbalance or bias in the underlying data or model assumptions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = chat.ai_respond('What kind does it detect?')\n",
    "display(Markdown(f'{output}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15900ad-eec1-4dca-bbad-94f167e91d33",
   "metadata": {},
   "source": [
    "---\n",
    "## Combining RAG with Conversation\n",
    "\n",
    "Now that we have a conversational system built, lets incorporate the RAG system we built in notebook 02 into the chat paradigm. \n",
    "\n",
    "First, we will create the same vector store with LangChain and FAISS from the last notebook.\n",
    "\n",
    "Our goal is to create a curated response from the model and only use the FAQ's we have provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "288ebfdf-9a20-43ae-9d20-0c82b7bc6974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# create instantiation to embedding model\n",
    "embedding_model = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=\"amazon.titan-embed-text-v1\"\n",
    ")\n",
    "\n",
    "# create vector store\n",
    "vs = FAISS.load_local('./faiss-index/langchain/', embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a47f0-cfc5-40ff-8899-fb53ad8c80d3",
   "metadata": {},
   "source": [
    "### Visualize Semantic Search \n",
    "\n",
    "⚠️ ⚠️ ⚠️ This section is for Advanced Practioners. Please feel free to run through these cells and come back later to re-examine the concepts ⚠️ ⚠️ ⚠️ \n",
    "\n",
    "Let's see how the semantic search works:\n",
    "1. First we calculate the embeddings vector for the query, and\n",
    "2. then we use this vector to do a similarity search on the store\n",
    "\n",
    "\n",
    "##### Citation\n",
    "We will also be able to get the `citation` or the underlying documents which our Vector Store matched to our query. This is useful for debugging and also measuring the quality of the vector stores. let us look at how the underlying Vector store calculates the matches\n",
    "\n",
    "##### Vector DB Indexes\n",
    "One of the key components of the Vector DB is to be able to retrieve documents matching the query with accuracy and speed. There are multiple algorithims for the same and some examples can be [read here](https://thedataquarry.com/posts/vector-db-3/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac922d8d-ce3c-49d8-abd8-8e002ecf61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#- helpful function to display in tabular format\n",
    "\n",
    "def display_table(data):\n",
    "    html = \"<table>\"\n",
    "    for row in data:\n",
    "        html += \"<tr>\"\n",
    "        for field in row:\n",
    "            html += \"<td>%s</td>\"%(field)\n",
    "        html += \"</tr>\"\n",
    "    html += \"</table>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94ad2894-de41-4ad9-a50b-af50d783a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14746094, 0.77734375, 0.26953125, -0.55859375, 0.047851562, -0.43554688, -0.057617188, -0.00030326843, -0.5703125, -0.33789062]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Let us look at the documents which had the relevant information pertaining to our query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "------------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "How do I build an ML model to generate accurate predictions in SageMaker Canvas?,\" Once you have connected sources, selected a dataset, and prepared your data, you can select the target column that you want to predict to initiate a model creation job. SageMaker Canvas will automatically identify the problem type, generate new relevant features, test a comprehensive set of prediction models using ML techniques such as linear regression, logistic regression, deep learning, time-series forecasting, and gradient boosting, and build the model that makes accurate predictions based on your dataset.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "------------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "v = embedding_model.embed_query(\"How can I check for imbalances in my model?\")\n",
    "print(v[0:10])\n",
    "results = vs.similarity_search_by_vector(v, k=2)\n",
    "display(Markdown('Let us look at the documents which had the relevant information pertaining to our query'))\n",
    "for r in results:\n",
    "    display(Markdown(f'{r.page_content}'))\n",
    "    display(Markdown(f'------------------------------------'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd40c8-7ab5-4c31-9aa3-5470ce608873",
   "metadata": {},
   "source": [
    "#### Similarity Search\n",
    "\n",
    "##### Distance scoring in Vector Data bases\n",
    "[Distance scores](https://weaviate.io/blog/distance-metrics-in-vector-search) are the key in vector searches. Here are some FAISS specific methods. One of them is similarity_search_with_score, which allows you to return not only the documents but also the distance score of the query to them. The returned distance score is L2 distance ( Squared Euclidean) . Therefore, a lower score is better. Further in FAISS we have similarity_search_with_score (ranked by distance: low to high) and similarity_search_with_relevance_scores ( ranked by relevance: high to low) with both using the distance strategy. The similarity_search_with_relevance_scores calculates the relevance score as 1 - score. For more details of the various distance scores [read here](https://milvus.io/docs/metric.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ce7ded-0f9f-4c80-8cdc-26760142bc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Let us look at the documents based on EUCLIDEAN_DISTANCE which will be used to answer our question 'What kind of bias does Clarify detect ?'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "------------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Documents</td><td>Meta-data</td></tr><tr><td>What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"</td><td>{}</td></tr><tr><td>How does SageMaker Clarify improve model explainability?, SageMaker Clarify is integrated with SageMaker Experiments to provide a feature importance graph detailing the importance of each input for your model’s overall decision-making process after the model has been trained. These details can help determine if a particular model input has more influence than it should on overall model behavior. SageMaker Clarify also makes explanations for individual predictions available through an API.</td><td>{}</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"##### Let us look at the documents based on {vs.distance_strategy.name} which will be used to answer our question 'What kind of bias does Clarify detect ?'\"))\n",
    "\n",
    "context = vs.similarity_search('What kind of bias does Clarify detect ?', k=2)\n",
    "#-  langchain.schema.document.Document\n",
    "display(Markdown(f'------------------------------------'))\n",
    "list_context = [[doc.page_content, doc.metadata] for doc in context]\n",
    "list_context.insert(0, ['Documents', 'Meta-data'])\n",
    "display_table(list_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520c885-be4e-4aaf-9a10-47fe1b039294",
   "metadata": {},
   "source": [
    "Let us first look at the Page context and the meta data associated with the documents. Now let us look at the L2 scores based on the distance scoring as explained above. Lower score is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bca4ab4-e8d3-40c3-821b-068543dcab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Similarity Search Table with relevancy score."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "------------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Documents</td><td>Relevancy Score</td></tr><tr><td>page_content='What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model\\'s prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"' _lc_kwargs={'page_content': 'What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model\\'s prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"', 'metadata': {}}</td><td>130.9253</td></tr><tr><td>page_content='How does SageMaker Clarify improve model explainability?, SageMaker Clarify is integrated with SageMaker Experiments to provide a feature importance graph detailing the importance of each input for your model’s overall decision-making process after the model has been trained. These details can help determine if a particular model input has more influence than it should on overall model behavior. SageMaker Clarify also makes explanations for individual predictions available through an API.' _lc_kwargs={'page_content': 'How does SageMaker Clarify improve model explainability?, SageMaker Clarify is integrated with SageMaker Experiments to provide a feature importance graph detailing the importance of each input for your model’s overall decision-making process after the model has been trained. These details can help determine if a particular model input has more influence than it should on overall model behavior. SageMaker Clarify also makes explanations for individual predictions available through an API.', 'metadata': {}}</td><td>188.70462</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#- relevancy of the documents\n",
    "results = vs.similarity_search_with_score(\"What kind of bias does Clarify detect ?\", k=2, fetch_k=3)\n",
    "display(Markdown(f'##### Similarity Search Table with relevancy score.'))\n",
    "display(Markdown(f'------------------------------------'))   \n",
    "results.insert(0,['Documents', 'Relevancy Score'])\n",
    "display_table(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7cad2-7426-4665-831e-d93722af2be5",
   "metadata": {},
   "source": [
    "#### Marginal Relevancy score\n",
    "\n",
    "Maximal Marginal Relevance  has been introduced in the paper [The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries](https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf). Maximal Marginal Relevance tries to reduce the redundancy of results while at the same time maintaining query relevance of results for already ranked documents/phrases etc. In the below results since we have a very limited data set it might not make a difference but for larger data sets the query will theoritically run faster while still preserving the over all relevancy of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "797351e5-189f-40c8-beaf-18806db973a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Let us look at MRR scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Document</td><td>MRR Score</td></tr><tr><td>page_content='What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model\\'s prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"' _lc_kwargs={'page_content': 'What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model\\'s prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"', 'metadata': {}}</td><td>130.9253</td></tr><tr><td>page_content='How does SageMaker Clarify improve model explainability?, SageMaker Clarify is integrated with SageMaker Experiments to provide a feature importance graph detailing the importance of each input for your model’s overall decision-making process after the model has been trained. These details can help determine if a particular model input has more influence than it should on overall model behavior. SageMaker Clarify also makes explanations for individual predictions available through an API.' _lc_kwargs={'page_content': 'How does SageMaker Clarify improve model explainability?, SageMaker Clarify is integrated with SageMaker Experiments to provide a feature importance graph detailing the importance of each input for your model’s overall decision-making process after the model has been trained. These details can help determine if a particular model input has more influence than it should on overall model behavior. SageMaker Clarify also makes explanations for individual predictions available through an API.', 'metadata': {}}</td><td>188.70462</td></tr><tr><td>page_content='What is the underlying tuning algorithm for Automatic Model Tuning?,\" Currently, the algorithm for tuning hyperparameters is a customized implementation of Bayesian Optimization. It aims to optimize a customer-specified objective metric throughout the tuning process. Specifically, it checks the object metric of completed training jobs, and uses the knowledge to infer the hyperparameter combination for the next training job.\"\\nDoes Automatic Model Tuning recommend specific hyperparameters for tuning?,\" No. How certain hyperparameters impact the model performance depends on various factors, and it is hard to definitively say one hyperparameter is more important than the others and thus needs to be tuned. For built-in algorithms within SageMaker, we do call out whether or not a hyperparameter is tunable.\"' _lc_kwargs={'page_content': 'What is the underlying tuning algorithm for Automatic Model Tuning?,\" Currently, the algorithm for tuning hyperparameters is a customized implementation of Bayesian Optimization. It aims to optimize a customer-specified objective metric throughout the tuning process. Specifically, it checks the object metric of completed training jobs, and uses the knowledge to infer the hyperparameter combination for the next training job.\"\\nDoes Automatic Model Tuning recommend specific hyperparameters for tuning?,\" No. How certain hyperparameters impact the model performance depends on various factors, and it is hard to definitively say one hyperparameter is more important than the others and thus needs to be tuned. For built-in algorithms within SageMaker, we do call out whether or not a hyperparameter is tunable.\"', 'metadata': {}}</td><td>281.98914</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#- normalizing the relevancy\n",
    "display(Markdown('##### Let us look at MRR scores'))\n",
    "results = vs.max_marginal_relevance_search_with_score_by_vector(embedding_model.embed_query(\"What kind of bias does Clarify detect ?\"), k=3)\n",
    "results.insert(0, [\"Document\", \"MRR Score\"])\n",
    "display_table(results)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022b736-d913-4d86-8dea-9dc7bac7a8ff",
   "metadata": {},
   "source": [
    "#### Update embeddings of the Vector Databases\n",
    "\n",
    "Update of documents happens all the time and we have multiple versions of the documents. Which means we need to also factor how do we update the embeddings in our Vector Data bases. Fortunately we have and can leverage the meta data to update embeddings\n",
    "\n",
    "The key steps are:\n",
    "1. Load the new embeddings and add the meta data stating the version as 2\n",
    "2. Merge to the exisiting Vector database\n",
    "3. Run the query using the filter to only search in the new index and get the latest documents for the same query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d713f8ef-0cac-45ef-b438-472033620fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split docs=6\n"
     ]
    }
   ],
   "source": [
    "# create vector store\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "loader = CSVLoader(\n",
    "    file_path=\"./data/sagemaker/sm_faq_v2.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "        \"fieldnames\": [\"Question\", \"Answer\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "#docs_split = loader.load()\n",
    "docs_split = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator=\",\").split_documents(loader.load())\n",
    "list_of_documents = [Document(page_content=doc.page_content, metadata=dict(page='v2')) for idx, doc in enumerate(docs_split)]\n",
    "print(f\"Number of split docs={len(docs_split)}\")\n",
    "db = FAISS.from_documents(list_of_documents, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e440b35-1003-4b3a-b4d7-c00a145bf202",
   "metadata": {},
   "source": [
    "#### Run a query against version 2 of the documents\n",
    "Let us run the query agsint our exisiting vector data base and we will see the the exisiting or the version 1 of the documents coming back. If we run with the filter since those do not exist in our vector Database we will see no results returned or an empty list back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a728a607-68e1-4228-8b63-72d063250b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "\n",
      "Running the query with V2 of the document we get []:\n"
     ]
    }
   ],
   "source": [
    "# Run the query with requesting data from version 2 which does not exist\n",
    "vs = FAISS.load_local('./faiss-index/langchain/', embedding_model, allow_dangerous_deserialization=True)\n",
    "search_query = \"How can I check for imbalances in my model?\"\n",
    "#print(f\"Running with v1 of the documents we get response of {vs.similarity_search_with_score(query=search_query, k=1, fetch_k=4)}\")\n",
    "print(\"------\\n\")\n",
    "print(f\"Running the query with V2 of the document we get {vs.similarity_search_with_score(query=search_query, filter=dict(page='v2'), k=1)}:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7048b90-e7c5-49e2-aadd-63777dd48371",
   "metadata": {},
   "source": [
    "#### Add a new version of the document\n",
    "We will create the version 2 of the documents and use meta data to add to our original index. Once done we will then apply a filter in our query which will return to us the documents newly added. Run the query now after adding version of the documents\n",
    "\n",
    "We will also examine a way to speed up our searches and queries and look at another way to narrow the search using the  fetch_k parameter when calling similarity_search with filters. Usually you would want the fetch_k to be more than the k parameter. This is because the fetch_k parameter is the number of documents that will be fetched before filtering. If you set fetch_k to a low number, you might not get enough documents to filter from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e06f8701-baa9-4eac-8e31-328d6626f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - now let us add version 2 of the data set and run query from that\n",
    "\n",
    "vs.merge_from(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d8719-9c70-47ee-92bd-ed5ebdc60610",
   "metadata": {},
   "source": [
    "#### Query complete merged data base with no filters\n",
    "Run the query against the fully merged DB without any filters for the meta data and we see that it returns the top results of the new V2 data and also the top results of the v1 data. Essentially it will match and return data closest to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01b48dea-3956-4545-b1e7-3f285994e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Document</td><td>Meta-Data</td><td>Score</td></tr><tr><td>Question: How can I check for imbalances in my model?\n",
       "Answer: Amazon SageMaker Clarify Version 2 will helps improve model transparency. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time</td><td>{'page': 'v2'}</td><td>154.83807</td></tr><tr><td>What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"</td><td>{}</td><td>229.07722</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - run the query again\n",
    "search_query_v2 = \"How can I check for imbalances in my model?\"\n",
    "results_with_scores = vs.similarity_search_with_score(search_query_v2, k=2, fetch_k=3)\n",
    "results_with_scores = [[doc.page_content, doc.metadata, score] for doc, score in results_with_scores]\n",
    "results_with_scores.insert(0, ['Document', 'Meta-Data', 'Score'])\n",
    "display_table(results_with_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0854172-3973-45be-9c02-cd780762608b",
   "metadata": {},
   "source": [
    "#### Query with Filter\n",
    "Now we will ask to search only against the version 2 of the data and use filter criteria against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1aff6f4d-f8b4-4ae0-9eff-6978a04a7124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Document</td><td>Meta-Data</td><td>Score</td></tr><tr><td>Question: How can I check for imbalances in my model?\n",
       "Answer: Amazon SageMaker Clarify Version 2 will helps improve model transparency. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time</td><td>{'page': 'v2'}</td><td>154.83807</td></tr><tr><td>Question: What kind of bias does SageMaker Clarify detect?\n",
       "Answer: Measuring bias in ML models is a first step to mitigating bias.</td><td>{'page': 'v2'}</td><td>268.9629</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - run the query again\n",
    "search_query_v2 = \"How can I check for imbalances in my model?\"\n",
    "results_with_scores = vs.similarity_search_with_score(search_query_v2, filter=dict(page='v2'), k=2, fetch_k=3)\n",
    "results_with_scores = [[doc.page_content, doc.metadata, score] for doc, score in results_with_scores]\n",
    "results_with_scores.insert(0, ['Document', 'Meta-Data', 'Score'])\n",
    "display_table(results_with_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac26ad-960f-4b08-aa4d-e62c87bacb27",
   "metadata": {},
   "source": [
    "#### Query for new data\n",
    "Now let us ask a question which exists only on the version 2 of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc60a62f-e5d6-4b55-ba14-88f82944e9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Document</td><td>Meta-Data</td><td>Score</td></tr><tr><td>Question: Can i use Quantum computing?\n",
       "Answer: Yes SageMaker version sometime in future will let you run quantum computing</td><td>{'page': 'v2'}</td><td>97.10315</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - now let us ask a question which ONLY exits in the version 2 of the document\n",
    "search_query_v2 = \"Can i use Quantum computing?\"\n",
    "results_with_scores = vs.similarity_search_with_score(query=search_query_v2, filter=dict(page='v2'), k=1, fetch_k=3)\n",
    "results_with_scores = [[doc.page_content, doc.metadata, score] for doc, score in results_with_scores]\n",
    "results_with_scores.insert(0, ['Document', 'Meta-Data', 'Score'])\n",
    "display_table(results_with_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b55be-1374-467f-aedc-d509c09aa101",
   "metadata": {},
   "source": [
    "### Let us continue to build our chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e90dd-aab0-4eed-b350-e906ae05f37c",
   "metadata": {},
   "source": [
    "The prompt template is now altered to include both conversation memory as well as chat history as inputs along with the human input. Notice how the prompt also instructs Claude to not answer questions which it does not have the context for. This helps reduce hallucinations which is extremely important when creating end user facing applications which need to be factual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c44e1-7dfc-46f7-a8fe-7e1ecbf23394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create vector store and continue\n",
    "vs = FAISS.load_local('./faiss-index/langchain/', embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16db7c3e-4196-44f3-9728-6410b4940678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAG_TEMPLATE = \"\"\"You are a helpful conversational assistant.\n",
    "\n",
    "If you are unsure about the answer OR the answer does not exist in the context, respond with\n",
    "\"Sorry but I do not understand your request. I am still learning so I appreciate your patience! 😊\n",
    "NEVER make up the answer.\n",
    "\n",
    "If the human greets you, simply introduce yourself.\n",
    "\n",
    "The context will be placed in <context></context> XML tags. \n",
    "\n",
    "<context>{context}</context>\n",
    "\n",
    "Do not include any xml tags in your response.\n",
    "\n",
    "{history}\n",
    "\n",
    "Human: {input}\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6516bf-5950-404e-bdce-3e26e200699c",
   "metadata": {},
   "source": [
    "The new `ConversationWithRetrieval` class now includes a `get_context` function which searches our vector database based on the human input and combines it into the base prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8538e7fb-e226-4d85-a413-0622ac53b578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConversationWithRetrieval:\n",
    "    def __init__(self, client, vector_store: FAISS=None, model_id: str=\"anthropic.claude-instant-v1\") -> None:\n",
    "        \"\"\"instantiates a new rag based conversation\n",
    "\n",
    "        Args:\n",
    "            vector_store (FAISS, optional): pre-populated vector store for searching context. Defaults to None.\n",
    "            model_id (str, optional): which bedrock model to use for the conversational agent. Defaults to \"anthropic.claude-instant-v1\".\n",
    "        \"\"\"\n",
    "\n",
    "        # store vector store\n",
    "        self.vector_store = vector_store\n",
    "        \n",
    "        # instantiate memory\n",
    "        self.memory = ConversationBufferMemory(human_prefix=\"Human\", ai_prefix=\"Assistant\")\n",
    "\n",
    "        # instantiate LLM connection\n",
    "        self.llm = Bedrock(\n",
    "            client=client,\n",
    "            model_id=model_id,\n",
    "            model_kwargs={\n",
    "                \"max_tokens_to_sample\": 500,\n",
    "                \"temperature\": 0.0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def ai_respond(self, user_input: str=None):\n",
    "        \"\"\"responds to the user input in the conversation with context used\n",
    "\n",
    "        Args:\n",
    "            user_input (str, optional): user input. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            ai_output (str): response from AI chatbot\n",
    "            search_results (list): context used in the completion\n",
    "        \"\"\"\n",
    "\n",
    "        # format the prompt with chat history and user input\n",
    "        context_string, search_results = self.get_context(user_input)\n",
    "        history = self.memory.load_memory_variables({})['history']\n",
    "        llm_input = PROMPT.format(history=history, input=user_input, context=context_string)\n",
    "\n",
    "        # respond to the user with the LLM\n",
    "        ai_output = self.llm(llm_input).strip()\n",
    "\n",
    "        # store the input and output\n",
    "        self.memory.chat_memory.add_user_message(user_input)\n",
    "        self.memory.chat_memory.add_ai_message(ai_output.strip())\n",
    "\n",
    "        return ai_output, search_results\n",
    "\n",
    "    def get_context(self, user_input, k=5):\n",
    "        \"\"\"returns context used in the completion\n",
    "\n",
    "        Args:\n",
    "            user_input (str): user input as a string\n",
    "            k (int, optional): number of results to return. Defaults to 5.\n",
    "\n",
    "        Returns:\n",
    "            context_string (str): context used in the completion as a string\n",
    "            search_results (list): context used in the completion as a list of Document objects\n",
    "        \"\"\"\n",
    "        search_results = self.vector_store.similarity_search(\n",
    "            user_input, k=k\n",
    "        )\n",
    "        context_string = '\\n\\n'.join([f'Document {ind+1}: ' + i.page_content for ind, i in enumerate(search_results)])\n",
    "        return context_string, search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ac1c0-bf12-40ef-adcb-9966225ce33d",
   "metadata": {},
   "source": [
    "Now the model can answer some specific domain questions based on our document database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f5c0c8b-b687-40d0-88e5-be01f940d5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ConversationWithRetrieval(boto3_bedrock, vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1597f990-80f2-4fa6-8869-d3560b91b25a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Amazon SageMaker Clarify Version 2 will helps improve model transparency. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time. Measuring bias in ML models is a first step to mitigating bias. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output, context = chat.ai_respond('How can I check for imbalances in my model?')\n",
    "display(Markdown(f'{output}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dfa6fb2-d153-470a-b7c8-9126804a31a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "** Ai Assistant Answer: ** \n",
       "SageMaker Clarify can detect different types of bias. Specifically, it can detect representational harms, predictive equality harms, and historical harms.\n",
       "\n",
       "- Representational harms refer to biases or imbalances in the training data that could influence the model, such as underrepresentation of certain groups. SageMaker Clarify can detect this type of bias by checking if one group is underrepresented compared to others in the training data.\n",
       "\n",
       "- Predictive equality harms refer to differences in how accurately or reliably a model performs for different groups. SageMaker Clarify can detect this type of bias by measuring metrics like error rates, precision, and recall and comparing the performance across different groups after model training or during deployment. \n",
       "\n",
       "- Historical harms refer to biases from past data or decisions that influence future outcomes in a unfair way. SageMaker Clarify can help detect this type of bias over time by monitoring model performance and metrics continuously during deployment to identify new biases or drifts in model behavior.\n",
       "\n",
       "So in summary, SageMaker Clarify can detect various types of biases like representational biases, predictive biases, and historical biases through different bias metrics computed during data preparation, after model training, and during model deployment and monitoring. This helps identify any unfair harms or inequalities in how the model treats different groups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "** Relevant Documentation: ** \n",
       "[Document(page_content='What is Amazon SageMaker Autopilot?,\" SageMaker Autopilot is the industry’s first automated machine learning capability that gives you complete control and visibility into your ML models. SageMaker Autopilot automatically inspects raw data, applies feature processors, picks the best set of algorithms, trains and tunes multiple models, tracks their performance, and then ranks the models based on performance, all with just a few clicks. The result is the best-performing model that you can deploy at a fraction of the time normally required to train the model. You get full visibility into how the model was created and what’s in it, and SageMaker Autopilot integrates with SageMaker Studio. You can explore up to 50 different models generated by SageMaker Autopilot inside SageMaker Studio so it’s easy to pick the best model for your use case. SageMaker Autopilot can be used by people without ML experience to easily produce a model, or it can be used by experienced developers to quickly develop a baseline model on which teams can further iterate.\"', _lc_kwargs={'page_content': 'What is Amazon SageMaker Autopilot?,\" SageMaker Autopilot is the industry’s first automated machine learning capability that gives you complete control and visibility into your ML models. SageMaker Autopilot automatically inspects raw data, applies feature processors, picks the best set of algorithms, trains and tunes multiple models, tracks their performance, and then ranks the models based on performance, all with just a few clicks. The result is the best-performing model that you can deploy at a fraction of the time normally required to train the model. You get full visibility into how the model was created and what’s in it, and SageMaker Autopilot integrates with SageMaker Studio. You can explore up to 50 different models generated by SageMaker Autopilot inside SageMaker Studio so it’s easy to pick the best model for your use case. SageMaker Autopilot can be used by people without ML experience to easily produce a model, or it can be used by experienced developers to quickly develop a baseline model on which teams can further iterate.\"', 'metadata': {}}), Document(page_content='What is Amazon SageMaker Studio Lab?,\" SageMaker Studio Lab is a free ML development environment that provides the compute, storage (up to 15 GB), and security—all at no cost—for anyone to learn and experiment with ML. All you need to get started is a valid email ID; you don’t need to configure infrastructure or manage identity and access or even sign up for an AWS account. SageMaker Studio Lab accelerates model building through GitHub integration, and it comes preconfigured with the most popular ML tools, frameworks, and libraries to get you started immediately. SageMaker Studio Lab automatically saves your work so you don’t need to restart between sessions. It’s as easy as closing your laptop and coming back later.\"', _lc_kwargs={'page_content': 'What is Amazon SageMaker Studio Lab?,\" SageMaker Studio Lab is a free ML development environment that provides the compute, storage (up to 15 GB), and security—all at no cost—for anyone to learn and experiment with ML. All you need to get started is a valid email ID; you don’t need to configure infrastructure or manage identity and access or even sign up for an AWS account. SageMaker Studio Lab accelerates model building through GitHub integration, and it comes preconfigured with the most popular ML tools, frameworks, and libraries to get you started immediately. SageMaker Studio Lab automatically saves your work so you don’t need to restart between sessions. It’s as easy as closing your laptop and coming back later.\"', 'metadata': {}}), Document(page_content='What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model\\'s prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"', _lc_kwargs={'page_content': 'What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model\\'s prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\"', 'metadata': {}}), Document(page_content='How can I reproduce a feature from a given moment in time?, SageMaker Feature Store maintains time stamps for all features at every instance of time. This helps you retrieve features at any period of time for business or compliance requirements. You can easily explain model features and their values from when they were first created to the present time by reproducing the model from a given moment in time.\\nWhat are offline features?,\" Offline features are used for training because you need access to very large volumes over a long period of time. These features are served from a high-throughput, high-bandwidth repository.\"\\nWhat are online features?, Online features are used in applications required to make real-time predictions. Online features are served from a high-throughput repository with single-digit millisecond latency for fast predictions.', _lc_kwargs={'page_content': 'How can I reproduce a feature from a given moment in time?, SageMaker Feature Store maintains time stamps for all features at every instance of time. This helps you retrieve features at any period of time for business or compliance requirements. You can easily explain model features and their values from when they were first created to the present time by reproducing the model from a given moment in time.\\nWhat are offline features?,\" Offline features are used for training because you need access to very large volumes over a long period of time. These features are served from a high-throughput, high-bandwidth repository.\"\\nWhat are online features?, Online features are used in applications required to make real-time predictions. Online features are served from a high-throughput repository with single-digit millisecond latency for fast predictions.', 'metadata': {}}), Document(page_content='Why should I use SageMaker for shadow testing?,\" SageMaker simplifies the process of setting up and monitoring shadow variants so you can evaluate the performance of the new ML model on live production traffic. SageMaker eliminates the need for you to orchestrate infrastructure for shadow testing. It lets you control testing parameters such as the percentage of traffic mirrored to the shadow variant and the duration of the test. As a result, you can start small and increase the inference requests to the new model after you gain confidence in model performance. SageMaker creates a live dashboard displaying performance differences across key metrics, so you can easily compare model performance to evaluate how the new model differs from the production model.\"', _lc_kwargs={'page_content': 'Why should I use SageMaker for shadow testing?,\" SageMaker simplifies the process of setting up and monitoring shadow variants so you can evaluate the performance of the new ML model on live production traffic. SageMaker eliminates the need for you to orchestrate infrastructure for shadow testing. It lets you control testing parameters such as the percentage of traffic mirrored to the shadow variant and the duration of the test. As a result, you can start small and increase the inference requests to the new model after you gain confidence in model performance. SageMaker creates a live dashboard displaying performance differences across key metrics, so you can easily compare model performance to evaluate how the new model differs from the production model.\"', 'metadata': {}})]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output, context = chat.ai_respond('What kind does it detect?')\n",
    "display(Markdown(f'** Ai Assistant Answer: ** \\n{output}'))\n",
    "display(Markdown(f'\\n\\n** Relevant Documentation: ** \\n{context}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ec2c2-1952-4073-975b-62ba36ac939e",
   "metadata": {},
   "source": [
    "--- \n",
    "## Using LangChain for Orchestration of RAG\n",
    "\n",
    "Beyond the primitive classes for prompt handling and conversational memory management, LangChain also provides a framework for [orchestrating RAG flows](https://python.langchain.com/docs/expression_language/cookbook/retrieval) with what purpose built \"chains\". In this section, we will see how to be a retrieval chain with LangChain which is more comprehensive and robust than the original retrieval system we built above.\n",
    "\n",
    "The workflow we used above follows the following process...\n",
    "\n",
    "1. User input is received.\n",
    "2. User input is queried against the vector database to retrieve relevant documents.\n",
    "3. Relevant documents and chat memory are inserted into a new prompt to respond to the user input.\n",
    "4. Return to step 1.\n",
    "\n",
    "However, more complex methods of interacting with the user input can generate more accurate results in RAG architectures. One of the popular mechanisms which can increase accuracy of these retrieval systems is utilizing more than one call to an LLM in order to reformat the user input for more effective search to your vector database. A better workflow is described below compared to the one we already built...\n",
    "\n",
    "1. User input is received.\n",
    "2. An LLM is used to reword the user input to be a better search query for the vector database based on the chat history and other instructions. This could include things like condensing, rewording, addition of chat context, or stylistic changes.\n",
    "3. Reformatted user input is queried against the vector database to retrieve relevant documents.\n",
    "4. The reformatted user input and relevant documents are inserted into a new prompt in order to answer the user question.\n",
    "5. Return to step 1.\n",
    "\n",
    "Let's now build out this second workflow using LangChain below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36910ae2-0a31-4463-903d-01739b59e299",
   "metadata": {},
   "source": [
    "First we need to make a prompt which will reformat the user input to be more compatible for searching of the vector database. The way we do this is by providing the chat history as well as the some basic instructions to Claude and asking it to condense the input into a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "188937eb-4496-405f-a797-90289295deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "condense_prompt = PromptTemplate.from_template(\"\"\"\\\n",
    "<chat-history>\n",
    "{chat_history}\n",
    "</chat-history>\n",
    "\n",
    "<follow-up-message>\n",
    "{question}\n",
    "<follow-up-message>\n",
    "\n",
    "Human: Given the conversation above (between Human and Assistant) and the follow up message from Human, \\\n",
    "rewrite the follow up message to be a standalone question that captures all relevant context \\\n",
    "from the conversation. Answer only with the new question and nothing else.\n",
    "\n",
    "Assistant: Standalone Question:\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb043fb-15db-4af8-827c-11a7a93c0085",
   "metadata": {},
   "source": [
    "The next prompt we need is the prompt which will answer the user's question based on the retrieved information. In this case, we provide specific instructions about how to answer the question as well as provide the context retrieved from the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7c83db2-1f80-4f74-8ec0-e51619831dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "respond_prompt = PromptTemplate.from_template(\"\"\"\\\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Human: Given the context above, answer the question inside the <q></q> XML tags.\n",
    "\n",
    "<q>{question}</q>\n",
    "\n",
    "If the answer is not in the context say \"Sorry, I don't know as the answer was not found in the context\". Do not use any XML tags in the answer.\n",
    "\n",
    "Assistant:\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad46697-6804-483d-a233-229670c7b5ea",
   "metadata": {},
   "source": [
    "Now that we have our prompts set up, let's set up the conversational memory buffer just like we did earlier in the notebook. Notice how we inject an example human and assistant message in order to help guide our AI assistant on what its job is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10c08e14-2b61-4e3d-a322-0054fcb572e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=\"anthropic.claude-instant-v1\",\n",
    "    model_kwargs={\"max_tokens_to_sample\": 500, \"temperature\": 0.9}\n",
    ")\n",
    "memory_chain = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    human_prefix=\"Human\",\n",
    "    ai_prefix=\"Assistant\"\n",
    ")\n",
    "memory_chain.chat_memory.add_user_message(\n",
    "    'Hello, what are you able to do?'\n",
    ")\n",
    "memory_chain.chat_memory.add_ai_message(\n",
    "    'Hi! I am a help chat assistant which can answer questions about Amazon SageMaker.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686208d-fecf-4cd2-b4dc-c70ae6ab2819",
   "metadata": {},
   "source": [
    "Lastly, we will used the `ConversationalRetrievalChain` from LangChain to orchestrate this whole system. If you would like to see some more logs about what is happening in the orchestration and not just the final output, make sure to change the `verbose` argument to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b239947-aa3e-4c83-9aea-9a954e880977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, # this is our claude model\n",
    "    retriever=vs.as_retriever(), # this is our FAISS vector database\n",
    "    memory=memory_chain, # this is the conversational memory storage class\n",
    "    condense_question_prompt=condense_prompt, # this is the prompt for condensing user inputs\n",
    "    verbose=False, # change this to True in order to see the logs working in the background\n",
    ")\n",
    "qa.combine_docs_chain.llm_chain.prompt = respond_prompt # this is the prompt in order to respond to condensed questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c1209-1805-48d9-8658-9c5d037654c8",
   "metadata": {},
   "source": [
    "Let's go ahead and generate some responses from our RAG solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc231e31-58d0-44ef-964c-0ba19c143d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " With Amazon SageMaker, you can check for imbalances in your model in a few ways:\n",
       "\n",
       "You can use Amazon SageMaker Clarify to check for imbalances during data preparation, after training, and ongoing over time. SageMaker Clarify will analyze your model and data to detect any potential biases, like disproportionate mispredictions for certain groups. \n",
       "\n",
       "You can also use SageMaker Studio to explore up to 50 different models generated by SageMaker Autopilot. This allows you to compare multiple models and evaluate things like if certain groups are predicted accurately compared to others. SageMaker Studio gives full visibility into how each model was created.\n",
       "\n",
       "Additionally, SageMaker Data Wrangler supports running bias analysis using SageMaker Clarify directly during the data preparation process. This lets you detect potential biases in the data before training models.\n",
       "\n",
       "So in summary, SageMaker Clarify, SageMaker Studio, SageMaker Autopilot and SageMaker Data Wrangler all provide capabilities to analyze models and data for imbalances or unintended biases towards specific groups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"{qa.run({'question': 'How can I check for imbalances in my model?'})}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d7bee05-531d-4d9d-8c69-0a397acd0a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " SageMaker Clarify, SageMaker Studio, SageMaker Autopilot and SageMaker Data Wrangler can detect the following types of imbalances in models and data:\n",
       "\n",
       "SageMaker Clarify can check for imbalances in the training data before and after model training, as well as for an inference model. It can detect differences in label distributions and underrepresentation across different groups in the training data. For trained models and deployed inferences, it can measure whether performance like error rates, precision and recall differ across groups. \n",
       "\n",
       "SageMaker Data Wrangler allows running bias analysis supported by SageMaker Clarify directly during data preparation to detect potential biases. \n",
       "\n",
       "SageMaker Autopilot and SageMaker Studio integrate with SageMaker Clarify, so they can explore up to 50 different models generated by Autopilot to help identify any performance imbalances across groups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"{qa.run({'question': 'What kind does it detect?' })}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "475359e0-21da-4a2c-9eaa-f45e6501e24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " SageMaker Clarify, SageMaker Studio, SageMaker Autopilot and SageMaker Data Wrangler help improve the explainability of Machine Learning models developed with Amazon SageMaker in the following ways:\n",
       "\n",
       "SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time. This helps identify any unfairness or biases in the training data or model. SageMaker Studio provides a single interface where all ML development steps can be performed, including using SageMaker Clarify to debug and explain models. SageMaker Autopilot automatically trains and tunes multiple models, then ranks them based on performance and transparency metrics from SageMaker Clarify. This helps produce the most fair and explainable model. SageMaker Data Wrangler allows preparing data for ML within SageMaker Studio, and can detect potential bias during this stage using SageMaker Clarify. Together, these capabilities give visibility into how data impacts the model and how to improve any issues, leading to more transparent and trustworthy models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"{qa.run({'question': 'How does this improve model explainability?' })}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6c109-965c-48eb-b585-7da66890c334",
   "metadata": {},
   "source": [
    "## Let us use LLM to validate if the response was factual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee1c03-a707-4e4f-bc97-365d2bde77c9",
   "metadata": {},
   "source": [
    "#### We first create a sanity prompt, which will use the vector DB results and ask the LLM to validate if the respinse given was acurate or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c1a6559-69e6-4289-9df5-7dcc80d41df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a conversation between a highly knowledgeable and intelligent AI assistant, called Falcon, and a human user asking Questions. In the following interactions, Falcon will converse in natural language, and Falcon will answer the questions based only on the provided Context. Falcon will provide accurate, short and direct answers to the questions.\n",
      "Context: {context}\n",
      "Statement: {statement}\n",
      "Question: Is the above statement based directly on the provided context? Answer with yes or no.\n",
      "Answer:\n",
      "Content: Question: How can I check for imbalances in my model?\n",
      "Answer: Amazon SageMaker Clarify Version 2 will helps improve model transparency. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time, Metadata: {'page': 'v2'}, Score: 154.83807373046875\n",
      "Content: What kind of bias does SageMaker Clarify detect?,\" Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You must choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\", Metadata: {}, Score: 229.0772247314453\n",
      "Content: Question: What kind of bias does SageMaker Clarify detect?\n",
      "Answer: Measuring bias in ML models is a first step to mitigating bias., Metadata: {'page': 'v2'}, Score: 268.962890625\n",
      "Content: How do I build an ML model to generate accurate predictions in SageMaker Canvas?,\" Once you have connected sources, selected a dataset, and prepared your data, you can select the target column that you want to predict to initiate a model creation job. SageMaker Canvas will automatically identify the problem type, generate new relevant features, test a comprehensive set of prediction models using ML techniques such as linear regression, logistic regression, deep learning, time-series forecasting, and gradient boosting, and build the model that makes accurate predictions based on your dataset.\", Metadata: {}, Score: 273.8197326660156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sanity check prompt\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "def create_sanity_prompt(instruction_start: str = None,instruction_end: str = None,) -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Create a prompt template for LLM sanity check\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instruction_start : str, optional\n",
    "        Instrcution in the beginning of the prompt, by default None\n",
    "    instruction_end : str, optional\n",
    "        Instrcution in the end of the prompt, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PromptTemplate\n",
    "        Prompt template in the LangChain format\n",
    "    \"\"\"\n",
    "\n",
    "    # first instruction\n",
    "    prompt_template_build = instruction_start + \"\\n\"\n",
    "\n",
    "    # add context\n",
    "    prompt_template_build += \"Context: {context}\" + \"\\n\"\n",
    "\n",
    "    # add statement\n",
    "    prompt_template_build += \"Statement: {statement}\" + \"\\n\"\n",
    "\n",
    "    # addinstruction\n",
    "    prompt_template_build += \"Question: \" + instruction_end + \"\\n\"\n",
    "\n",
    "    # add answer placeholder\n",
    "    prompt_template_build += \"Answer:\"\n",
    "\n",
    "    print(prompt_template_build)\n",
    "    # build the template\n",
    "    llm_prompt = PromptTemplate(\n",
    "        template=str(prompt_template_build),\n",
    "        input_variables=[\"context\", \"statement\"],\n",
    "    )\n",
    "    return llm_prompt\n",
    "\n",
    "sanity_prompt = create_sanity_prompt(\n",
    "    instruction_start=\"\"\"The following is a conversation between a highly knowledgeable and intelligent AI assistant, called Falcon, and a human user asking Questions. In the following interactions, Falcon will converse in natural language, and Falcon will answer the questions based only on the provided Context. Falcon will provide accurate, short and direct answers to the questions.\"\"\",\n",
    "    instruction_end=\"Is the above statement based directly on the provided context? Answer with yes or no.\",\n",
    ")\n",
    "\n",
    "docs = vs.similarity_search_with_score('How can I check for imbalances in my model?')\n",
    "contexts = []\n",
    "source = []\n",
    "for doc, score in docs:\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")\n",
    "    if score <= 0.9:\n",
    "        contexts.append(doc)\n",
    "        source.append(doc.metadata['source'])\n",
    "        print(f\"\\n INPUT CONTEXT:{contexts}\")\n",
    "\n",
    "sanity_chain = load_qa_chain(llm=llm, prompt=sanity_prompt)\n",
    "sanity_check = sanity_chain({\"input_documents\": contexts, \"statement\": output},return_only_outputs=True)['output_text']\n",
    "\n",
    "sanity_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156cf9a-1ed0-4a43-9339-1e12a02ac126",
   "metadata": {},
   "source": [
    "#### We can see the Vector database responded accurately to our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a907835c-524a-4fe6-af3c-a58d6f4c2b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
