{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c56efea-5831-48db-8ad8-dd962cf67d78",
   "metadata": {},
   "source": [
    "# Embeddings Type Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b28c2c-85aa-4c59-b79e-473c12673e91",
   "metadata": {},
   "source": [
    "## Setup and Introduction\n",
    "\n",
    "Embeddings are dense vector representations of data (often words, sentences, or documents) in a continuous vector space. They capture semantic meaning and relationships between items in a way that's useful for machine learning models. In essence, embeddings translate high-dimensional, sparse data into lower-dimensional, dense vectors where similar items are closer together in the vector space. Now lets look at several types of embeddings:\n",
    "\n",
    "**Float Embeddings**: They are the most common and traditional type of embeddings. They use floating-point numbers (typically 32-bit or 64-bit) to represent each dimension of the embedding vector, offering high precision but requiring more storage and computational resources. They're the standard for most machine learning tasks\n",
    "\n",
    "**Int8 Embeddings**: Int8 embeddings use 8-bit integers instead of floating-point numbers. This is a form of quantization, providing a good balance between precision and efficiency. They reduce memory usage and can speed up computations, making them suitable for resource-constrained environments.\n",
    "\n",
    "**Binary Embeddings**: Represent each dimension with a single bit (0 or 1), resulting in extremely compact and fast-to-process embeddings. While they sacrifice precision, they excel in large-scale similarity search tasks.\n",
    "\n",
    "This notebook demonstrates a comparison between the three types of embeddings: float embeddings, int8 embeddings, and binary embeddings. Cohere embbeding model on Amazon Bedrock is used to generate these embeddings and then we will compare their memory footprint and retrieval speed. The vector databases that are used are OpenSearch and FAISS (Facebook AI Similarity Search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4405175c-0fa8-4c50-a9ba-28e9561db90e",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df708bfc-829b-4395-937f-4a03d28cc80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.85 requires botocore==1.34.85, but you have botocore 1.34.152 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet boto3 pandas datasets faiss-cpu opensearch-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2722df-dee1-425a-a399-b6d497dabcc5",
   "metadata": {},
   "source": [
    "## Setup Bedrock Client\n",
    "\n",
    "The `invoke_bedrock` function is set up to interact with Amazon Bedrock's API. It sends requests to generate embeddings for given texts using the specified embedding types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9f541e0-b076-414d-b7aa-0991dad05322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "def invoke_bedrock(texts, input_type, embedding_types, model_id=\"cohere.embed-english-v3\"):\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body= json.dumps({\n",
    "            \"texts\": texts,\n",
    "            \"input_type\": input_type,\n",
    "            \"truncate\": \"END\",\n",
    "            \"embedding_types\": embedding_types\n",
    "        }),\n",
    "    \tmodelId=model_id,\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    embedding_output = response_body.get(\"embeddings\")\n",
    "    response_type = response_body.get(\"response_type\")\n",
    "    \n",
    "    return embedding_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5259bce-960f-4d8e-9edb-a6798bb86d10",
   "metadata": {},
   "source": [
    "## Setup dataset\n",
    "\n",
    "We use the [MSMARCO dataset](https://huggingface.co/datasets/microsoft/ms_marco), a large-scale dataset for information retrieval tasks. We load a subset of this dataset, extracting passages and queries for our embedding experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "444507d3-0fcd-4d5f-8e0e-3293fc5cea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the MSMARCO dataset from Hugging Face\n",
    "dataset = load_dataset(\"ms_marco\", \"v2.1\", split=\"train[:96]\")\n",
    "passages = dataset['passages']\n",
    "corpus = [ passage[\"passage_text\"][0] for passage in passages ]\n",
    "queries = dataset['query']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1369c6-dda5-434f-bb9d-bb50a908f657",
   "metadata": {},
   "source": [
    "## Vector Embedding Memory Footprint\n",
    "\n",
    "This section demonstrates how different embedding types affect memory usage.\n",
    "\n",
    "The `calculate_embedding_memory` function computes the memory footprint of embeddings based on their type (float, int8, or binary). It calculates the total size, embedding dimension, number of embeddings, and size of each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bef857e-8a14-45ed-a664-0d95b8b126de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_embedding_memory(embeddings, embed_type=\"float\"):\n",
    "\n",
    "    if embed_type == \"float\":\n",
    "        data_type=np.float32\n",
    "    elif embed_type == \"int8\":\n",
    "        data_type=np.int8\n",
    "    elif embed_type == \"ubinary\":\n",
    "        data_type=np.uint8\n",
    "\n",
    "    embeddings_np = np.array(embeddings).astype(data_type)\n",
    "    num_embeddings, embedding_dim = embeddings_np.shape\n",
    "    \n",
    "    # Get the size of each element in bytes\n",
    "    element_size = embeddings_np.itemsize\n",
    "    \n",
    "    # Calculate the total size\n",
    "    total_size = num_embeddings * embedding_dim * element_size\n",
    "    \n",
    "    return total_size, embedding_dim, num_embeddings, element_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429f4d6-d534-40f5-9bb9-2df06691f3e8",
   "metadata": {},
   "source": [
    "### Float embeddings\n",
    "\n",
    "Float embeddings are the standard output of most embedding models. They use 32 bits (4 bytes) per dimension, providing high precision but requiring more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "010142e3-7450-4b2f-8ffe-318a70e8a4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size: 393216 bytes\n",
      "Total Size (MB): 0.375 MB\n",
      "Size of each embedding dimension: 4 byte(s)\n",
      "Embeddings dimension: 1024\n",
      "Number of embeddings: 96\n"
     ]
    }
   ],
   "source": [
    "embed_type=\"float\"\n",
    "response= invoke_bedrock(corpus, input_type=\"search_document\", embedding_types=[embed_type])\n",
    "embeddings_float = response[embed_type]\n",
    "\n",
    "# Calculate memory\n",
    "total_size_float, embedding_dim, num_embeddings, element_size = calculate_embedding_memory(embeddings_float, embed_type)\n",
    "total_size_float_mb = total_size_float / (1024 * 1024)\n",
    "\n",
    "print(f\"Total Size: {total_size_float} bytes\")\n",
    "print(f\"Total Size (MB): {total_size_float_mb} MB\")\n",
    "print(f\"Size of each embedding dimension: {element_size} byte(s)\")\n",
    "print(f\"Embeddings dimension: {embedding_dim}\")\n",
    "print(f\"Number of embeddings: {num_embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b954e6-83e2-43b1-b804-a6d7788dd512",
   "metadata": {},
   "source": [
    "### int8 embeddings\n",
    "\n",
    "Int8 embeddings quantize the float embeddings to 8-bit integers. This reduces memory usage to 1 byte per dimension, potentially sacrificing some precision for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d439af9-06e8-4ff2-ba8a-f3f876d9ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size: 98304 bytes\n",
      "Total Size (MB): 0.09375 MB\n",
      "Size of each embedding dimension: 1 byte(s)\n",
      "Embeddings dimension: 1024\n",
      "Number of embeddings: 96\n"
     ]
    }
   ],
   "source": [
    "embed_type=\"int8\"\n",
    "response= invoke_bedrock(corpus, input_type=\"search_document\", embedding_types=[embed_type])\n",
    "embeddings_int8 = response[embed_type]\n",
    "\n",
    "# Calculate memory\n",
    "total_size_int8, embedding_dim, num_embeddings, element_size = calculate_embedding_memory(embeddings_int8, embed_type)\n",
    "total_size_int8_mb = total_size_int8 / (1024 * 1024)\n",
    "\n",
    "print(f\"Total Size: {total_size_int8} bytes\")\n",
    "print(f\"Total Size (MB): {total_size_int8_mb} MB\")\n",
    "print(f\"Size of each embedding dimension: {element_size} byte(s)\")\n",
    "print(f\"Embeddings dimension: {embedding_dim}\")\n",
    "print(f\"Number of embeddings: {num_embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5743b-fd84-4e75-b5cb-4ddc237fc5eb",
   "metadata": {},
   "source": [
    "### Binary embeddings\n",
    "\n",
    "Binary embeddings further compress the representation to 1 bit per dimension. While this dramatically reduces memory usage, it may lead to a more significant loss in precision compared to float or int8 embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fb98626-6142-4b44-b2d2-7e47f498f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size: 12288 bytes\n",
      "Total Size (MB): 0.01171875 MB\n",
      "Size of each embedding dimension: 1 byte(s)\n",
      "Embeddings dimension: 128\n",
      "Number of embeddings: 96\n"
     ]
    }
   ],
   "source": [
    "embed_type=\"ubinary\"\n",
    "response= invoke_bedrock(corpus, input_type=\"search_document\", embedding_types=[embed_type])\n",
    "embeddings_binary = response[embed_type]\n",
    "\n",
    "# Calculate memory\n",
    "total_size_binary, embedding_dim, num_embeddings, element_size = calculate_embedding_memory(embeddings_binary, embed_type)\n",
    "total_size_binary_mb = total_size_binary / (1024 * 1024)\n",
    "\n",
    "print(f\"Total Size: {total_size_binary} bytes\")\n",
    "print(f\"Total Size (MB): {total_size_binary_mb} MB\")\n",
    "print(f\"Size of each embedding dimension: {element_size} byte(s)\")\n",
    "print(f\"Embeddings dimension: {embedding_dim}\")\n",
    "print(f\"Number of embeddings: {num_embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e1dab-c07d-4649-8a73-09845abd0639",
   "metadata": {},
   "source": [
    "### Comparing Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5095c827-d18f-472f-8b1a-2a72b7cd2bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b19bc_row0_col0, #T_b19bc_row0_col1, #T_b19bc_row0_col2, #T_b19bc_row1_col0, #T_b19bc_row1_col1, #T_b19bc_row1_col2, #T_b19bc_row2_col0, #T_b19bc_row2_col1, #T_b19bc_row2_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b19bc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b19bc_level0_col0\" class=\"col_heading level0 col0\" >Embedding Type</th>\n",
       "      <th id=\"T_b19bc_level0_col1\" class=\"col_heading level0 col1\" >Total Size (Bytes)</th>\n",
       "      <th id=\"T_b19bc_level0_col2\" class=\"col_heading level0 col2\" >Total Size (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b19bc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b19bc_row0_col0\" class=\"data row0 col0\" >Float Embeddings</td>\n",
       "      <td id=\"T_b19bc_row0_col1\" class=\"data row0 col1\" >393216</td>\n",
       "      <td id=\"T_b19bc_row0_col2\" class=\"data row0 col2\" >0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b19bc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b19bc_row1_col0\" class=\"data row1 col0\" >Int8 Embeddings</td>\n",
       "      <td id=\"T_b19bc_row1_col1\" class=\"data row1 col1\" >98304</td>\n",
       "      <td id=\"T_b19bc_row1_col2\" class=\"data row1 col2\" >0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b19bc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b19bc_row2_col0\" class=\"data row2 col0\" >Binary Embeddings</td>\n",
       "      <td id=\"T_b19bc_row2_col1\" class=\"data row2 col1\" >12288</td>\n",
       "      <td id=\"T_b19bc_row2_col2\" class=\"data row2 col2\" >0.011719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f83f5f94d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Embedding Type\": [\"Float Embeddings\", \"Int8 Embeddings\", \"Binary Embeddings\"],\n",
    "    \"Total Size (Bytes)\": [total_size_float, total_size_int8, total_size_binary],\n",
    "    \"Total Size (MB)\": [total_size_float_mb, total_size_int8_mb, total_size_binary_mb]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df.style.set_properties(**{'text-align': 'left'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32b417-9fde-46fe-af4c-230d52bfdc48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieval Speed\n",
    "\n",
    "This section compares the retrieval speed of different embedding types using OpenSearch and FAISS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c45ce1-0970-4baa-b5ba-6541e920d06c",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "**Before running this cell below, ensure to have Opensearch cluster running. For simplicity, you can deploy an opensearch cluster on the same host where this notebook is running using Docker**\n",
    "\n",
    "`docker run -d -p 9200:9200 -p 9600:9600 -e \"discovery.type=single-node\" opensearchproject/opensearch:2.11.1`\n",
    "\n",
    "Below we use the default `user: admin` and `password: admin`. You might need to replace the host/port/username/password if OpenSearch is hosted somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cabcc3f9-2eb3-451d-80ea-7fba8049d91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, helpers\n",
    "import time \n",
    "\n",
    "#Disable SSL warnings from OpenSearch\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def create_os_index(index_name, index_body, documents, embeddings):\n",
    "    \n",
    "    # Here we use the default user: admin and password: admin\n",
    "    # You might need to replace the host/port/username/password if OpenSearch is hosted somewhere else\n",
    "    os_client = OpenSearch(\n",
    "        hosts=[{'host': 'localhost', 'port': 9200}],\n",
    "        http_auth=('admin', 'admin'),\n",
    "        use_ssl=True,\n",
    "        verify_certs=False\n",
    "    )\n",
    "    \n",
    "    # Delete the index if it exists already\n",
    "    os_client.indices.delete(index=index_name, ignore=[400, 404])\n",
    "    \n",
    "    # Create the new index\n",
    "    response = os_client.indices.create(index_name, body=index_body)\n",
    "    print(\"OpenSearch index created:\", response)\n",
    "    \n",
    "    # We use a batch size of 512, embed the documents and then index this to OpenSearch\n",
    "    batch_size = 512\n",
    "    doc_id = 0\n",
    "    for start_idx in range(0, len(documents), batch_size):\n",
    "        batch_documents = documents[start_idx:start_idx+batch_size]\n",
    "\n",
    "        # Do a bulk upsert to OpenSearch\n",
    "        batch = []\n",
    "        for document, doc_emb in zip(batch_documents, embeddings):\n",
    "            batch.append({\n",
    "                    \"_index\": index_name,\n",
    "                    \"_id\": doc_id,\n",
    "                    \"_source\": {\n",
    "                        \"text\": document,\n",
    "                        \"text_emb\": doc_emb\n",
    "                    }\n",
    "                })\n",
    "            doc_id += 1\n",
    "        helpers.bulk(os_client, batch)\n",
    "\n",
    "    print(\"Indexing of documents finished\")\n",
    "    \n",
    "    # Give opensearch some time to index the data\n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "def query_os(index_name, query_emb, top_k=5):\n",
    "    \n",
    "    query_body = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "            \"text_emb\": {\n",
    "                \"vector\": query_emb,\n",
    "                \"k\": top_k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    hits = os_client.search(index=index_name, body=query_body)[\"hits\"][\"hits\"]\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_secs = f\"{elapsed_time:.6f} seconds\"\n",
    "    \n",
    "    return hits, elapsed_time_secs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0ad9b-1688-417c-9a68-c52a36d4ecdf",
   "metadata": {},
   "source": [
    "### float embeddings\n",
    "\n",
    "We create an Opensearch index using float embeddings and perform a search. This serves as a baseline for comparison with other embedding types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5238844b-b3ba-4087-a998-6a23f3f8fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/opensearchpy/connection/http_urllib3.py:214: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch index created: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'index-float'}\n",
      "Indexing of documents finished\n",
      "Time taken for retrieval: 0.011233 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_type=\"float\"\n",
    "index_name = \"index-float\"\n",
    "\n",
    "index_body = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'number_of_shards': 1,\n",
    "            \"knn\": True,\n",
    "            \"knn.algo_param.ef_search\": 100\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"text_emb\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "create_os_index(index_name, index_body, corpus, embeddings_float)\n",
    "\n",
    "# Search in your index. First we define the query\n",
    "query = queries[0]\n",
    "response = invoke_bedrock([query], input_type=\"search_query\", embedding_types=[embed_type])\n",
    "query_emb = np.array(response[embed_type]).astype('int8')[0]\n",
    "\n",
    "hits, response_time_float = query_os(index_name, query_emb)\n",
    "\n",
    "print(f\"Time taken for retrieval: {response_time_float}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf4a2b-b78f-4241-99c4-0ba3fe27bf61",
   "metadata": {},
   "source": [
    "### int8 embeddings\n",
    "\n",
    "Int8 embeddings are used to create a opensearch index. The search performance is compared to the float embeddings baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f41f8645-0835-4903-ab24-6d0471bb3788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch index created: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'index-int8'}\n",
      "Indexing of documents finished\n",
      "Time taken for retrieval: 0.008207 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_type=\"int8\"\n",
    "index_name = \"index-int8\"\n",
    "\n",
    "# We specify a 'text_emb' property, that has \"data_type\": \"byte\". As engine we must use Lucene \n",
    "index_body = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'number_of_shards': 1,\n",
    "            \"knn\": True,\n",
    "            \"knn.algo_param.ef_search\": 100\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"text_emb\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,      #Use 1024 for the large models, 384 for the light models\n",
    "                \"data_type\": \"byte\",    #Set data_type as byte\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"cosinesimil\",\n",
    "                    \"engine\": \"lucene\", #Set Lucene as your engine\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 256,\n",
    "                        \"m\": 48\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "create_os_index(index_name, index_body, corpus, embeddings_int8)\n",
    "\n",
    "# Search in your index. First we define the query\n",
    "query = queries[0]\n",
    "response = invoke_bedrock([query], input_type=\"search_query\", embedding_types=[embed_type])\n",
    "query_emb = np.array(response[embed_type]).astype('int8')[0]\n",
    "\n",
    "hits, response_time_int8 = query_os(index_name, query_emb)\n",
    "\n",
    "print(f\"Time taken for retrieval: {response_time_int8}\\n\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e1dcb-1171-4943-b432-f9bbf3715cc0",
   "metadata": {},
   "source": [
    "### Binary embeddings\n",
    "\n",
    "Opensearch does not support storing binary embeddings, so for this we will utilize FAISS for this. A binary FAISS index is created using binary embeddings and search is performed.\n",
    "\n",
    "**It is important to note that FAISS is an in memory vector store so search will be typically faster when compared with searching an opensearch cluster, so this is not an apples to apples comparison like we did with the float embeddings and int8 embeddings. However this is still shown to demonstrate how search will be performed for binary embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc0ff3de-d518-4cb5-9ba0-b9e6380d804e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for retrieval: 0.000177 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import time\n",
    "\n",
    "embed_type=\"ubinary\"\n",
    "\n",
    "#Cast embeddings to numpy\n",
    "embeddings_bin = np.array(embeddings_binary).astype('uint8')\n",
    "\n",
    "#Add the embeddings to the faiss index\n",
    "num_dim = 1024   #Use 1024 dimensions for the embed-english-v3.0\n",
    "index = faiss.IndexBinaryFlat(num_dim)\n",
    "index.add(embeddings_bin)\n",
    "\n",
    "# Search in your index\n",
    "query = queries[0]\n",
    "response= invoke_bedrock([query], input_type=\"search_query\", embedding_types=[embed_type])\n",
    "query_emb = np.array(response[embed_type]).astype('uint8')\n",
    "\n",
    "start_time = time.time()\n",
    "hits_scores, hits_doc_ids = index.search(query_emb, k=min(10*5, index.ntotal))\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "response_time_binary = f\"{elapsed_time:.6f} seconds\"\n",
    "print(f\"Time taken for retrieval: {response_time_binary}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d7e4c-765c-4c24-a3b7-858b4697b409",
   "metadata": {},
   "source": [
    "### Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4caf37d9-c832-4f4b-93ba-84fe98baa2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8371b_row0_col0, #T_8371b_row0_col1, #T_8371b_row1_col0, #T_8371b_row1_col1, #T_8371b_row2_col0, #T_8371b_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8371b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8371b_level0_col0\" class=\"col_heading level0 col0\" >Embedding Type</th>\n",
       "      <th id=\"T_8371b_level0_col1\" class=\"col_heading level0 col1\" >Retrieval Speed (Seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8371b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8371b_row0_col0\" class=\"data row0 col0\" >Float Embeddings</td>\n",
       "      <td id=\"T_8371b_row0_col1\" class=\"data row0 col1\" >0.011233 seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8371b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8371b_row1_col0\" class=\"data row1 col0\" >Int8 Embeddings</td>\n",
       "      <td id=\"T_8371b_row1_col1\" class=\"data row1 col1\" >0.008207 seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8371b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8371b_row2_col0\" class=\"data row2 col0\" >Binary Embeddings (With FAISS)</td>\n",
       "      <td id=\"T_8371b_row2_col1\" class=\"data row2 col1\" >0.000177 seconds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f838aad7310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Embedding Type\": [\"Float Embeddings\", \"Int8 Embeddings\", \"Binary Embeddings (With FAISS)\"],\n",
    "    \"Retrieval Speed (Seconds)\": [response_time_float, response_time_int8, response_time_binary]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df.style.set_properties(**{'text-align': 'left'}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
